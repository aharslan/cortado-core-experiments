{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T15:45:09.372924700Z",
     "start_time": "2024-01-23T15:45:09.229947700Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from cortado_core.process_tree_utils.miscellaneous import get_height, get_number_nodes\n",
    "from pm4py.objects.petri_net.importer.importer import deserialize as deserialize_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T15:45:09.388926800Z",
     "start_time": "2024-01-23T15:45:09.358824500Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_theme(font=\"Arial\", style=\"whitegrid\", rc={\"figure.figsize\": (5, 4)})\n",
    "\n",
    "\n",
    "folder_name = \"rtfm\"\n",
    "folder_path = f\"./results/{folder_name}\"\n",
    "pickle_files = [\n",
    "    file for file in os.listdir(folder_path) if file.endswith(\"final.pickle\")\n",
    "]\n",
    "pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T15:45:09.990799200Z",
     "start_time": "2024-01-23T15:45:09.385926500Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(\n",
    "        folder_path,\n",
    "        [file_name for file_name in pickle_files if \"inductive_miner\" in file_name][0],\n",
    "    ),\n",
    "    \"rb\",\n",
    ") as file:\n",
    "    data = pickle.load(file)\n",
    "    variants_percentages = [100 * i / (len(data)) for i in range(len(data))]\n",
    "    variant_frequencies = np.array(\n",
    "        list(map(lambda iteration: iteration[\"added_variant_frequency\"], data))\n",
    "    )\n",
    "    trace_percentages = (variant_frequencies / variant_frequencies.sum() * 100).cumsum()\n",
    "\n",
    "fitness_df = pd.DataFrame(\n",
    "    {\n",
    "        \"% processed variants\": variants_percentages,\n",
    "        \"% processed traces\": trace_percentages,\n",
    "    }\n",
    ")\n",
    "precision_df = pd.DataFrame(\n",
    "    {\n",
    "        \"% processed variants\": variants_percentages,\n",
    "        \"% processed traces\": trace_percentages,\n",
    "    }\n",
    ")\n",
    "f_measure_df = pd.DataFrame(\n",
    "    {\n",
    "        \"% processed variants\": variants_percentages,\n",
    "        \"% processed traces\": trace_percentages,\n",
    "    }\n",
    ")\n",
    "height_df = pd.DataFrame(\n",
    "    {\n",
    "        \"% processed variants\": variants_percentages,\n",
    "        \"% processed traces\": trace_percentages,\n",
    "    }\n",
    ")\n",
    "nodes_df = pd.DataFrame(\n",
    "    {\n",
    "        \"% processed variants\": variants_percentages,\n",
    "        \"% processed traces\": trace_percentages,\n",
    "    }\n",
    ")\n",
    "pn_size_df = pd.DataFrame(\n",
    "    {\n",
    "        \"% processed variants\": variants_percentages,\n",
    "        \"% processed traces\": trace_percentages,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for file_name in pickle_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # if len(file_path.split(\"__\")) == 5:\n",
    "    # log_name, approach, initial_method, result_type, ending = file_path.split(\"__\")\n",
    "    if len(file_path.split(\"__\")) == 4:\n",
    "        log_name, approach, initial_method, ending = file_path.split(\"__\")\n",
    "        initial_method = initial_method.split(\".\")[-1]\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "        nan_values = [None] * (len(variants_percentages) - len(data))\n",
    "        fitness_ds = pd.Series(\n",
    "            nan_values + list(map(lambda iteration: iteration[\"fitness\"], data)),\n",
    "            name=f\"{approach}__{initial_method}\",\n",
    "        )\n",
    "        precision_ds = pd.Series(\n",
    "            nan_values + list(map(lambda iteration: iteration[\"precision\"], data)),\n",
    "            name=f\"{approach}__{initial_method}\",\n",
    "        )\n",
    "        f_measure_ds = pd.Series(\n",
    "            nan_values + list(map(lambda iteration: iteration[\"f-measure\"], data)),\n",
    "            name=f\"{approach}__{initial_method}\",\n",
    "        )\n",
    "        height_ds = pd.Series(\n",
    "            nan_values\n",
    "            + list(\n",
    "                map(\n",
    "                    lambda iteration: get_height(iteration[\"output_tree\"])\n",
    "                    if iteration[\"output_tree\"] is not None\n",
    "                    else None,\n",
    "                    data,\n",
    "                )\n",
    "            ),\n",
    "            name=f\"{approach}__{initial_method}\",\n",
    "        )\n",
    "        nodes_ds = pd.Series(\n",
    "            nan_values\n",
    "            + list(\n",
    "                map(\n",
    "                    lambda iteration: get_number_nodes(iteration[\"output_tree\"])\n",
    "                    if iteration[\"output_tree\"] is not None\n",
    "                    else None,\n",
    "                    data,\n",
    "                )\n",
    "            ),\n",
    "            name=f\"{approach}__{initial_method}\",\n",
    "        )\n",
    "        pn_size_ds = pd.Series(\n",
    "            nan_values\n",
    "            + list(\n",
    "                map(\n",
    "                    lambda iteration: len(\n",
    "                        deserialize_pn(iteration[\"output_model\"])[0].places\n",
    "                    )\n",
    "                    + len(deserialize_pn(iteration[\"output_model\"])[0].transitions)\n",
    "                    if iteration[\"output_model\"] is not None\n",
    "                    else None,\n",
    "                    data,\n",
    "                )\n",
    "            ),\n",
    "            name=f\"{approach}__{initial_method}\",\n",
    "        )\n",
    "\n",
    "        fitness_df = pd.concat([fitness_df, fitness_ds], axis=1)\n",
    "        precision_df = pd.concat([precision_df, precision_ds], axis=1)\n",
    "        f_measure_df = pd.concat([f_measure_df, f_measure_ds], axis=1)\n",
    "        height_df = pd.concat([height_df, height_ds], axis=1)\n",
    "        nodes_df = pd.concat([nodes_df, nodes_ds], axis=1)\n",
    "        pn_size_df = pd.concat([pn_size_df, pn_size_ds], axis=1)\n",
    "\n",
    "dfs = [fitness_df, precision_df, f_measure_df, height_df, nodes_df, pn_size_df]\n",
    "for df in dfs:\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].fillna(df[\"inductive_miner__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T15:45:10.004028200Z",
     "start_time": "2024-01-23T15:45:09.992800500Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_results(\n",
    "    df, initial_method, y_label, x_axis=\"% processed variants\", y_bottom_lim=0\n",
    "):\n",
    "    column_name_mapping = {\n",
    "        f\"incremental_lca_False__{initial_method}\": \"LCA-IPDA (w/o LCA lowering)\",\n",
    "        f\"incremental_lca_True__{initial_method}\": \"LCA-IPDA (w LCA lowering)\",\n",
    "        f\"naive__{initial_method}\": \"Naive IPDA\",\n",
    "        \"inductive_miner__\": \"Inductive Miner (IM)\",\n",
    "        f\"model_repair__{initial_method}\": \"Model Repair\",\n",
    "    }\n",
    "    filtered_df = df.filter(items=list(column_name_mapping.keys()) + [x_axis])\n",
    "    renamed_df = filtered_df.rename(columns=column_name_mapping)\n",
    "    for col in column_name_mapping.values():\n",
    "        sns.lineplot(\n",
    "            renamed_df,\n",
    "            x=x_axis,\n",
    "            y=col,\n",
    "            dashes=False,\n",
    "            label=col,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlim(-1, 101)\n",
    "    plt.ylim(y_bottom_lim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T15:45:10.020221100Z",
     "start_time": "2024-01-23T15:45:10.006012100Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_tree_measure(df, initial_method, y_label, x_axis=\"% processed variants\"):\n",
    "    column_name_mapping = {\n",
    "        f\"incremental_lca_False__{initial_method}\": \"LCA-IPDA (w/o LCA lowering)\",\n",
    "        f\"incremental_lca_True__{initial_method}\": \"LCA-IPDA (w LCA lowering)\",\n",
    "        f\"naive__{initial_method}\": \"Naive IPDA\",\n",
    "        \"inductive_miner__\": \"Inductive Miner (IM)\",\n",
    "    }\n",
    "    filtered_df = df.filter(items=list(column_name_mapping.keys()) + [x_axis])\n",
    "    renamed_df = filtered_df.rename(columns=column_name_mapping)\n",
    "    for col in column_name_mapping.values():\n",
    "        sns.lineplot(\n",
    "            renamed_df,\n",
    "            x=x_axis,\n",
    "            y=col,\n",
    "            dashes=False,\n",
    "            label=col,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlim(-1, 101)\n",
    "    plt.ylim(bottom=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pn_measure(df, initial_method, y_label, x_axis=\"% processed variants\"):\n",
    "    column_name_mapping = {\n",
    "        f\"incremental_lca_False__{initial_method}\": \"LCA-IPDA (w/o LCA lowering)\",\n",
    "        f\"incremental_lca_True__{initial_method}\": \"LCA-IPDA (w LCA lowering)\",\n",
    "        f\"naive__{initial_method}\": \"Naive IPDA\",\n",
    "        \"inductive_miner__\": \"Inductive Miner (IM)\",\n",
    "        f\"model_repair__{initial_method}\": \"Model Repair\",\n",
    "    }\n",
    "    filtered_df = df.filter(items=list(column_name_mapping.keys()) + [x_axis])\n",
    "    renamed_df = filtered_df.rename(columns=column_name_mapping)\n",
    "    for col in column_name_mapping.values():\n",
    "        sns.lineplot(\n",
    "            renamed_df,\n",
    "            x=x_axis,\n",
    "            y=col,\n",
    "            dashes=False,\n",
    "            label=col,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlim(-1, 101)\n",
    "    plt.ylim(bottom=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T15:45:21.352192500Z",
     "start_time": "2024-01-23T15:45:10.023221100Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_methods = {\n",
    "    \"TOP_1\": 0,\n",
    "    \"TOP_1_PERCENT\": 1,\n",
    "    \"TOP_2_PERCENT\": 2,\n",
    "    \"TOP_5_PERCENT\": 5,\n",
    "    \"TOP_10_PERCENT\": 10,\n",
    "}\n",
    "\n",
    "\n",
    "def create_plots(x_axis=\"% processed variants\"):\n",
    "    for initial_method, starting_percent in initial_methods.items():\n",
    "        mask = f_measure_df[\"% processed variants\"] >= starting_percent\n",
    "        last_false_index = (mask == True).idxmax() - 1\n",
    "        mask[last_false_index] = True\n",
    "\n",
    "        plt.figure()\n",
    "        min = (\n",
    "            floor(\n",
    "                precision_df.drop(\n",
    "                    [\"% processed variants\", \"% processed traces\"], axis=1\n",
    "                ).min(axis=None)\n",
    "                * 10\n",
    "            )\n",
    "            / 10\n",
    "        )\n",
    "        plot_results(precision_df[mask], initial_method, \"precision\", x_axis, min)\n",
    "        plt.savefig(\n",
    "            f\"figures/{folder_name}/{initial_method.lower()}_precision_{x_axis.split()[-1]}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "        plt.figure()\n",
    "        min = (\n",
    "            floor(\n",
    "                fitness_df.drop(\n",
    "                    [\"% processed variants\", \"% processed traces\"], axis=1\n",
    "                ).min(axis=None)\n",
    "                * 10\n",
    "            )\n",
    "            / 10\n",
    "        )\n",
    "        plot_results(fitness_df[mask], initial_method, \"fitness\", x_axis, min)\n",
    "        plt.savefig(\n",
    "            f\"figures/{folder_name}/{initial_method.lower()}_fitness_{x_axis.split()[-1]}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "        plt.figure()\n",
    "        min = (\n",
    "            floor(\n",
    "                f_measure_df.drop(\n",
    "                    [\"% processed variants\", \"% processed traces\"], axis=1\n",
    "                ).min(axis=None)\n",
    "                * 10\n",
    "            )\n",
    "            / 10\n",
    "        )\n",
    "        plot_results(f_measure_df[mask], initial_method, \"F-measure\", x_axis, min)\n",
    "        plt.savefig(\n",
    "            f\"figures/{folder_name}/{initial_method.lower()}_f-measure_{x_axis.split()[-1]}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "        plt.figure()\n",
    "        plot_tree_measure(height_df[mask], initial_method, \"tree height\", x_axis)\n",
    "        plt.savefig(\n",
    "            f\"figures/{folder_name}/{initial_method.lower()}_heights_{x_axis.split()[-1]}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "        plt.figure()\n",
    "        plot_tree_measure(nodes_df[mask], initial_method, \"no. of nodes\", x_axis)\n",
    "        plt.savefig(\n",
    "            f\"figures/{folder_name}/{initial_method.lower()}_nodes_{x_axis.split()[-1]}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "        plt.figure()\n",
    "        plot_pn_measure(pn_size_df[mask], initial_method, \"Petri net size\", x_axis)\n",
    "        plt.savefig(\n",
    "            f\"figures/{folder_name}/{initial_method.lower()}_pn_size_{x_axis.split()[-1]}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(\"% processed variants\")\n",
    "create_plots(\"% processed traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cortado-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
