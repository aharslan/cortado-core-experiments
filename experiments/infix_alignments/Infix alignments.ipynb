{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b08e9a7",
   "metadata": {},
   "source": [
    "# CCC 19 Model to process tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.petri_net.importer import importer as pnml_importer\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py.objects.conversion.wf_net import converter as wf_net_converter\n",
    "from pm4py.objects.process_tree.exporter import exporter as ptml_exporter\n",
    "\n",
    "net, im, fm = pnml_importer.apply(\"ccc19_model.pnml\")\n",
    "\n",
    "gviz = pn_visualizer.apply(net, im, fm)\n",
    "pn_visualizer.view(gviz)\n",
    "\n",
    "tree = wf_net_converter.apply(net, im, fm)\n",
    "print(tree)\n",
    "\n",
    "ptml_exporter.apply(tree, \"ccc19_process_tree.ptml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf7b29",
   "metadata": {},
   "source": [
    "# Generate parallel event logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.simulation.tree_generator import simulator as tree_gen\n",
    "\n",
    "\n",
    "def create_trees_with_parallel_probabilities(\n",
    "    relative_parallel_probabilities, n_trees_per_probability=10\n",
    "):\n",
    "    trees = dict()\n",
    "\n",
    "    for relative_parallel_node in relative_parallel_nodes:\n",
    "        other_probabilty = (1 - relative_parallel_node) / 3\n",
    "        parameters = {\n",
    "            \"mode\": 10,\n",
    "            \"min\": 10,\n",
    "            \"max\": 10,\n",
    "            \"choice\": other_probabilty,\n",
    "            \"sequence\": other_probabilty,\n",
    "            \"parallel\": relative_parallel_node,\n",
    "            \"loop\": other_probabilty,\n",
    "            \"no_models\": n_trees_per_probability,\n",
    "        }\n",
    "        trees[relative_parallel_node] = tree_gen.apply(parameters=parameters)\n",
    "\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.obj import Trace, Event, EventLog\n",
    "import random\n",
    "\n",
    "\n",
    "def get_distinct_activities_from_log(log):\n",
    "    distinct_activities = set()\n",
    "\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            distinct_activities.add(event[\"concept:name\"])\n",
    "\n",
    "    return distinct_activities\n",
    "\n",
    "\n",
    "def add_deviations_to_log(log, trace_probability, event_probability, action_dist):\n",
    "    assert sum(action_dist.values()) <= 1\n",
    "\n",
    "    distinct_activities = list(get_distinct_activities_from_log(log))\n",
    "    new_log = EventLog()\n",
    "\n",
    "    for trace in log:\n",
    "        if random.random() > trace_probability:\n",
    "            continue\n",
    "\n",
    "        new_trace = Trace()\n",
    "\n",
    "        for event in trace:\n",
    "            if random.random() > event_probability:\n",
    "                new_trace.append(event)\n",
    "                continue\n",
    "\n",
    "            event_action_prop = random.random()\n",
    "\n",
    "            if event_action_prop <= action_dist[\"before\"]:\n",
    "                e = Event()\n",
    "                e[\"concept:name\"] = random.choices(distinct_activities)[0]\n",
    "                new_trace.append(e)\n",
    "                new_trace.append(event)\n",
    "            elif event_action_prop <= action_dist[\"before\"] + action_dist[\"after\"]:\n",
    "                new_trace.append(event)\n",
    "                e = Event()\n",
    "                e[\"concept:name\"] = random.choices(distinct_activities)[0]\n",
    "                new_trace.append(e)\n",
    "            else:\n",
    "                e = Event()\n",
    "                e[\"concept:name\"] = random.choices(distinct_activities)[0]\n",
    "                new_trace.append(e)\n",
    "\n",
    "        new_log.append(new_trace)\n",
    "\n",
    "    return new_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe071c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.process_tree.utils.generic import parse\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "from pm4py.objects.process_tree import semantics\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.process_tree.exporter import exporter as ptml_exporter\n",
    "\n",
    "\n",
    "def generate_log_for_pt(tree, log_name, no_traces=1000, plot_tree=True):\n",
    "    if plot_tree:\n",
    "        gviz = pt_visualizer.apply(\n",
    "            tree,\n",
    "            parameters={\n",
    "                pt_visualizer.Variants.WO_DECORATION.value.Parameters.FORMAT: \"png\"\n",
    "            },\n",
    "        )\n",
    "        pt_visualizer.view(gviz)\n",
    "\n",
    "    log = semantics.generate_log(tree, no_traces=no_traces)\n",
    "    log = add_deviations_to_log(log, 0.3, 0.2, {\"before\": 0.25, \"after\": 0.25})\n",
    "    xes_exporter.apply(log, log_name + \".xes\")\n",
    "    ptml_exporter.apply(tree, log_name + \".ptml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_parallel_nodes = [i / 10 for i in range(11)]\n",
    "trees_dict = create_trees_with_parallel_probabilities(relative_parallel_nodes)\n",
    "\n",
    "for prop, trees in trees_dict.items():\n",
    "    for i, tree in enumerate(trees):\n",
    "        generate_log_for_pt(tree, f\"logs_parallel/log_parallel_{prop}_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac068031",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f16782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=0.8)\n",
    "\n",
    "ALGORITHM_BASELINE_DIJKSTRA = \"BASELINE_DIJKSTRA\"\n",
    "ALGORITHM_BASELINE_A_STAR = \"BASELINE_A_STAR\"\n",
    "ALGORITHM_TP_DIJKSTRA_NAIVE = \"TP_DIJKSTRA_NAIVE\"\n",
    "ALGORITHM_TP_DIJKSTRA_NOT_NAIVE = \"TP_DIJKSTRA_NOT_NAIVE\"\n",
    "ALGORITHM_TP_DIJKSTRA_NOT_NAIVE_ENFORCE_FIRST_TAU = (\n",
    "    \"TP_DIJKSTRA_NOT_NAIVE_ENFORCE_FIRST_TAU_MOVE\"\n",
    ")\n",
    "ALGORITHM_TP_A_STAR_NAIVE = \"TP_A_STAR_NAIVE\"\n",
    "ALGORITHM_TP_A_STAR_NOT_NAIVE = \"TP_A_STAR_NOT_NAIVE\"\n",
    "ALGORITHM_TP_A_STAR_NOT_NAIVE_ENFORCE_FIRST_TAU = (\n",
    "    \"TP_A_STAR_NOT_NAIVE_ENFORCE_FIRST_TAU_MOVE\"\n",
    ")\n",
    "\n",
    "ALGORITHMS = [\n",
    "    ALGORITHM_BASELINE_DIJKSTRA,\n",
    "    ALGORITHM_BASELINE_A_STAR,\n",
    "    ALGORITHM_TP_DIJKSTRA_NAIVE,\n",
    "    ALGORITHM_TP_DIJKSTRA_NOT_NAIVE,\n",
    "    ALGORITHM_TP_A_STAR_NAIVE,\n",
    "    ALGORITHM_TP_A_STAR_NOT_NAIVE,\n",
    "    ALGORITHM_TP_DIJKSTRA_NOT_NAIVE_ENFORCE_FIRST_TAU,\n",
    "    ALGORITHM_TP_A_STAR_NOT_NAIVE_ENFORCE_FIRST_TAU,\n",
    "]\n",
    "ALGORITHMS_A_STAR = [alg for alg in ALGORITHMS if \"A_STAR\" in alg]\n",
    "ALGORITHMS_DIJKSTRA = [alg for alg in ALGORITHMS if \"DIJKSTRA\" in alg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a123ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RESULTS = \"./results_09\"\n",
    "# RESULTS = ''\n",
    "# FILENAME = 'BPI_CH_2020_PrepaidTravelCost'\n",
    "# FILENAME = 'BPI_Challenge_2012'\n",
    "# FILENAME = 'BPI_Challenge_2019'\n",
    "# FILENAME = 'ccc19'\n",
    "# FILENAME = 'hospital_billing'\n",
    "# FILENAME = 'receipt'\n",
    "# FILENAME = 'RoadTrafficFineManagement'\n",
    "FILENAME = \"sepsis_cases\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "Path(os.path.join(RESULTS, \"plots\", FILENAME)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results_df = pd.read_csv(os.path.join(RESULTS, FILENAME + \"_infix_results.csv\"))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9e811",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pm4py.objects.process_tree.importer import importer as ptml_importer\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "\n",
    "tree = ptml_importer.apply(os.path.join(RESULTS, FILENAME + \".ptml\"))\n",
    "\n",
    "gviz = pt_visualizer.apply(\n",
    "    tree,\n",
    "    parameters={pt_visualizer.Variants.WO_DECORATION.value.Parameters.FORMAT: \"png\"},\n",
    ")\n",
    "pt_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove longest 2% of infixes\n",
    "\n",
    "long_df = results_df[[\"Infix\", \"Infix Length\"]].groupby(by=[\"Infix\"]).max()\n",
    "n_infixes_to_remove = math.ceil(len(long_df) / 100) * 2\n",
    "infixes_to_remove = set()\n",
    "\n",
    "for i in range(n_infixes_to_remove):\n",
    "    max_idx = long_df[\"Infix Length\"].idxmax()\n",
    "    infixes_to_remove.add(max_idx)\n",
    "    long_df = long_df.drop(index=max_idx)\n",
    "\n",
    "results_df = results_df[~results_df[\"Infix\"].isin(infixes_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "results_df[\"Distinct Activities\"] = results_df.apply(\n",
    "    lambda row: len(set(re.findall(\"'(.*?)'\", row[\"Infix\"]))), axis=1\n",
    ")\n",
    "results_df[\"SPN State Space Size\"] = results_df[\"State Space Size\"] * (\n",
    "    results_df[\"Infix Length\"] + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "BASELINE_LABEL = \"Baseline approach\"\n",
    "NAIVE_LABEL = \"Naive approach\"\n",
    "ADVANCED_LABEL = \"Advanced approach\"\n",
    "ADVANCED_FIRST_MODEL_LABEL = \"Advanced approach + pruning + forcing model move\"\n",
    "\n",
    "DIJKSTRA_RENAMINGS = {\n",
    "    ALGORITHM_BASELINE_DIJKSTRA: BASELINE_LABEL,\n",
    "    ALGORITHM_TP_DIJKSTRA_NAIVE: NAIVE_LABEL,\n",
    "    ALGORITHM_TP_DIJKSTRA_NOT_NAIVE: ADVANCED_LABEL,\n",
    "    ALGORITHM_TP_DIJKSTRA_NOT_NAIVE_ENFORCE_FIRST_TAU: ADVANCED_FIRST_MODEL_LABEL,\n",
    "}\n",
    "\n",
    "A_STAR_RENAMINGS = {\n",
    "    ALGORITHM_BASELINE_A_STAR: BASELINE_LABEL,\n",
    "    ALGORITHM_TP_A_STAR_NAIVE: NAIVE_LABEL,\n",
    "    ALGORITHM_TP_A_STAR_NOT_NAIVE: ADVANCED_LABEL,\n",
    "    ALGORITHM_TP_A_STAR_NOT_NAIVE_ENFORCE_FIRST_TAU: ADVANCED_FIRST_MODEL_LABEL,\n",
    "}\n",
    "\n",
    "ALGORITHMS_A_STAR_BASELINE_AND_ADVANCED = ALGORITHMS_A_STAR.copy()\n",
    "ALGORITHMS_A_STAR_BASELINE_AND_ADVANCED.remove(\n",
    "    ALGORITHM_TP_A_STAR_NOT_NAIVE_ENFORCE_FIRST_TAU\n",
    ")\n",
    "ALGORITHMS_A_STAR_BASELINE_AND_ADVANCED.remove(ALGORITHM_TP_A_STAR_NAIVE)\n",
    "\n",
    "ALGORITHMS_DIJKSTRA_BASELINE_AND_ADVANCED = ALGORITHMS_DIJKSTRA.copy()\n",
    "ALGORITHMS_DIJKSTRA_BASELINE_AND_ADVANCED.remove(\n",
    "    ALGORITHM_TP_DIJKSTRA_NOT_NAIVE_ENFORCE_FIRST_TAU\n",
    ")\n",
    "ALGORITHMS_DIJKSTRA_BASELINE_AND_ADVANCED.remove(ALGORITHM_TP_DIJKSTRA_NAIVE)\n",
    "\n",
    "plot_configs = [\n",
    "    (\"DIJKSTRA\", ALGORITHMS_DIJKSTRA, DIJKSTRA_RENAMINGS, 2),\n",
    "    (\n",
    "        \"DIJKSTRA_BASELINE_VS_ADVANCED\",\n",
    "        ALGORITHMS_DIJKSTRA_BASELINE_AND_ADVANCED,\n",
    "        DIJKSTRA_RENAMINGS,\n",
    "        2,\n",
    "    ),\n",
    "    (\"A_STAR\", ALGORITHMS_A_STAR, A_STAR_RENAMINGS, 2),\n",
    "    (\n",
    "        \"A_STAR_BASELINE_VS_ADVANCED\",\n",
    "        ALGORITHMS_A_STAR_BASELINE_AND_ADVANCED,\n",
    "        A_STAR_RENAMINGS,\n",
    "        2,\n",
    "    ),\n",
    "]\n",
    "\n",
    "sns_palette = sns.color_palette()\n",
    "palette = {\n",
    "    BASELINE_LABEL: sns_palette[0],\n",
    "    NAIVE_LABEL: sns_palette[2],\n",
    "    ADVANCED_LABEL: sns_palette[1],\n",
    "    ADVANCED_FIRST_MODEL_LABEL: sns_palette[3],\n",
    "}\n",
    "\n",
    "for name, algorithms, renaming, n_cols in plot_configs:\n",
    "    Path(os.path.join(RESULTS, \"plots\", FILENAME, name)).mkdir(\n",
    "        parents=True, exist_ok=True\n",
    "    )\n",
    "\n",
    "    for with_outliers in [True, False]:\n",
    "        d = results_df.copy()\n",
    "        d = results_df[results_df[\"Algorithm\"].isin(algorithms)]\n",
    "\n",
    "        d[\"Infix Length Bin\"] = pd.cut(d[\"Infix Length\"], bins=6)\n",
    "        d[\"Infix Length Bin Formatted\"] = d[\"Infix Length Bin\"].apply(\n",
    "            lambda d: str(math.floor(d.left) + 1) + \"-\" + str(math.floor(d.right))\n",
    "        )\n",
    "        for curr_name, renamed_name in renaming.items():\n",
    "            d.loc[d[\"Algorithm\"] == curr_name, \"Algorithm\"] = renamed_name\n",
    "\n",
    "        attributes_with_title = [\n",
    "            (\"Consumed Time\", \"Consumed Time (in seconds)\", True),\n",
    "            (\"Preprocessing Duration\", \"Preprocessing Duration (in seconds)\", True),\n",
    "            (\"Alignment Duration\", \"Alignment Duration (in seconds)\", True),\n",
    "            (\"Visited States\", \"Visited States\", True),\n",
    "            (\"Queued States\", \"Queued States\", True),\n",
    "            (\"Added Tau Transitions\", \"Added Tau Transitions\", False),\n",
    "            (\"SPN State Space Size\", \"SPN State Space Size\", False),\n",
    "        ]\n",
    "\n",
    "        for attribute, y_label, should_save in attributes_with_title:\n",
    "            figure(figsize=(6.3, 4))\n",
    "            sns.boxplot(\n",
    "                data=d,\n",
    "                x=\"Infix Length Bin Formatted\",\n",
    "                y=attribute,\n",
    "                hue=\"Algorithm\",\n",
    "                palette=palette,\n",
    "                showfliers=with_outliers,\n",
    "            )\n",
    "            y_legend = 1.15 if n_cols == 2 and len(algorithms) > 2 else 1.09\n",
    "            plt.legend(\n",
    "                bbox_to_anchor=(0, y_legend), loc=2, borderaxespad=0.0, ncol=n_cols\n",
    "            )\n",
    "            plt.xlabel(\"Infix Length\")\n",
    "            plt.ylabel(y_label)\n",
    "            if should_save:\n",
    "                outlier_extension = \"\"\n",
    "                if not with_outliers:\n",
    "                    outlier_extension = \" without outliers\"\n",
    "                plt.savefig(\n",
    "                    os.path.join(\n",
    "                        RESULTS,\n",
    "                        \"plots\",\n",
    "                        FILENAME,\n",
    "                        name,\n",
    "                        attribute + outlier_extension + \".pdf\",\n",
    "                    ),\n",
    "                    bbox_inches=\"tight\",\n",
    "                )\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-deviating infixes:\", len(results_df[results_df[\"Cost\"] < 10000]))\n",
    "print(\"Deviating infixes:\", len(results_df[results_df[\"Cost\"] >= 10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c63de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"Infix Length\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"Distinct Activities\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b36423",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_per_length_df_a_star = (\n",
    "    results_df[results_df[\"Algorithm\"].isin(ALGORITHMS_A_STAR)]\n",
    "    .groupby(by=[\"Infix Length\", \"Algorithm\"])\n",
    "    .mean()\n",
    ")\n",
    "mean_per_length_df_dijkstra = (\n",
    "    results_df[results_df[\"Algorithm\"].isin(ALGORITHMS_DIJKSTRA)]\n",
    "    .groupby(by=[\"Infix Length\", \"Algorithm\"])\n",
    "    .mean()\n",
    ")\n",
    "mean_dfs = [\n",
    "    (\"A Star\", mean_per_length_df_a_star),\n",
    "    (\"Dijkstra\", mean_per_length_df_dijkstra),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_with_title = [\n",
    "    (\"Consumed Time\", \"Mean consumed time per infix length\"),\n",
    "    (\"Preprocessing Duration\", \"Mean preprocessing duration per infix length\"),\n",
    "    (\"Alignment Duration\", \"Mean alignment duration per infix length\"),\n",
    "    (\"Visited States\", \"Mean visited states per infix length\"),\n",
    "    (\"Queued States\", \"Mean queued states per infix length\"),\n",
    "    # ('LP Solved', 'Mean solved linear programs'),\n",
    "    (\"Added Tau Transitions\", \"Mean added tau transitions per infix length\"),\n",
    "]\n",
    "\n",
    "for attribute, title in attributes_with_title:\n",
    "    for search_alg, mean_df in mean_dfs:\n",
    "        # sns.lineplot(data=mean_df.loc[pd.IndexSlice[0:60,:],:], x='Infix Length', y=attribute, hue='Algorithm', marker='.')\n",
    "        sns.lineplot(\n",
    "            data=mean_df, x=\"Infix Length\", y=attribute, hue=\"Algorithm\", marker=\".\"\n",
    "        )\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "        plt.title(title + \" (\" + search_alg + \")\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df[\"Algorithm\"] == ALGORITHM_TP_A_STAR_NAIVE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee12c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in ALGORITHMS_DIJKSTRA:\n",
    "    filtered_df = (\n",
    "        results_df[results_df[\"Algorithm\"] == alg].groupby(by=[\"Infix Length\"]).mean()\n",
    "    )\n",
    "    x = filtered_df.index\n",
    "    y = [filtered_df[\"Preprocessing Duration\"], filtered_df[\"Alignment Duration\"]]\n",
    "\n",
    "    plt.stackplot(x, y, labels=[\"Preprocessing Duration\", \"Alignment Duration\"])\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xlabel(\"Infix Length\")\n",
    "    plt.ylabel(\"Duration\")\n",
    "    plt.title(\"Mean duration: \" + alg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [\n",
    "    \"Infix Length\",\n",
    "    \"Consumed Time\",\n",
    "    \"Preprocessing Duration\",\n",
    "    \"Alignment Duration\",\n",
    "    \"Visited States\",\n",
    "]\n",
    "datasets = [\n",
    "    results_df[results_df[\"Algorithm\"] == alg][[\"Infix\"] + columns_of_interest]\n",
    "    for alg in ALGORITHMS\n",
    "]\n",
    "for i in range(len(datasets)):\n",
    "    for column in columns_of_interest:\n",
    "        datasets[i] = datasets[i].rename(columns={column: column + \"_\" + ALGORITHMS[i]})\n",
    "\n",
    "merged_df = datasets[0]\n",
    "for i in range(1, len(datasets)):\n",
    "    merged_df = merged_df.merge(datasets[i], on=\"Infix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in [\n",
    "    \"Consumed Time\",\n",
    "    \"Preprocessing Duration\",\n",
    "    \"Alignment Duration\",\n",
    "    \"Visited States\",\n",
    "]:\n",
    "    df = merged_df.copy()\n",
    "    df[variable + \" Dijkstra: Baseline - TP_Naive\"] = (\n",
    "        df[variable + \"_\" + ALGORITHM_BASELINE_DIJKSTRA]\n",
    "        - df[variable + \"_\" + ALGORITHM_TP_DIJKSTRA_NAIVE]\n",
    "    )\n",
    "    df[variable + \" Dijkstra: Baseline - TP_Not_Naive\"] = (\n",
    "        df[variable + \"_\" + ALGORITHM_BASELINE_DIJKSTRA]\n",
    "        - df[variable + \"_\" + ALGORITHM_TP_DIJKSTRA_NOT_NAIVE]\n",
    "    )\n",
    "    df[\"Infix Length\"] = df[\"Infix Length_\" + ALGORITHM_BASELINE_DIJKSTRA]\n",
    "\n",
    "    mean_per_length_df = pd.melt(\n",
    "        df,\n",
    "        id_vars=[\"Infix\", \"Infix Length\"],\n",
    "        value_vars=[\n",
    "            variable + \" Dijkstra: Baseline - TP_Naive\",\n",
    "            variable + \" Dijkstra: Baseline - TP_Not_Naive\",\n",
    "        ],\n",
    "        value_name=variable,\n",
    "        var_name=\"alg\",\n",
    "    )\n",
    "    mean_per_length_df = mean_per_length_df.groupby(by=[\"Infix Length\", \"alg\"]).mean()\n",
    "    sns.lineplot(\n",
    "        data=mean_per_length_df, x=\"Infix Length\", y=variable, hue=\"alg\", marker=\".\"\n",
    "    )\n",
    "    plt.ylabel(variable + \" difference\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "    plt.title(variable + \": Baseline - Algorithm (mean)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57665691",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df[\"Infix\"] == results_df.iloc[8057][\"Infix\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df[\"Preprocessing Duration\"] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b693951",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.iloc[2750][\"Infix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c483d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pm4py.visualization.transition_system import visualizer as ts_visualizer\n",
    "from pm4py.objects.petri_net.utils import reachability_graph\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "\n",
    "net, im, fm = pt_converter.apply(tree)\n",
    "ts = reachability_graph.construct_reachability_graph(net, im)\n",
    "gviz = ts_visualizer.apply(\n",
    "    ts, parameters={ts_visualizer.Variants.VIEW_BASED.value.Parameters.FORMAT: \"png\"}\n",
    ")\n",
    "ts_visualizer.view(gviz)\n",
    "print(\"States in reachability graph:\", len(ts.states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_each_algorithm(plotting_func):\n",
    "    for algorithm in ALGORITHMS:\n",
    "        plotting_func(results_df[results_df[\"Algorithm\"] == algorithm])\n",
    "        plt.title(algorithm)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff681b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=results_df, x=\"Consumed Time\", hue=\"Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_func = lambda d: sns.histplot(data=d, x=\"Consumed Time\")\n",
    "plot_for_each_algorithm(plotting_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9ac58",
   "metadata": {},
   "source": [
    "## Results for synthetic parallel trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "amount_parallel_nodes = [i / 10 for i in range(11)]\n",
    "parallel_df = None\n",
    "\n",
    "for amount_parallel in amount_parallel_nodes:\n",
    "    for i in range(10):\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(\n",
    "                \"./results_parallel\",\n",
    "                f\"log_parallel_{amount_parallel}_{i}_infix_results.csv\",\n",
    "            )\n",
    "        )\n",
    "        df = df[\n",
    "            [\n",
    "                \"Infix Length\",\n",
    "                \"Preprocessing Duration\",\n",
    "                \"Algorithm\",\n",
    "                \"Alignment Duration\",\n",
    "            ]\n",
    "        ]\n",
    "        df[\"Amount Parallelism\"] = amount_parallel\n",
    "        df[\"Original Log\"] = i\n",
    "\n",
    "        if parallel_df is None:\n",
    "            parallel_df = df\n",
    "        else:\n",
    "            parallel_df = pd.concat([parallel_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = parallel_df[parallel_df[\"Algorithm\"].isin(ALGORITHMS_DIJKSTRA)]\n",
    "sns.boxplot(data=d, x=\"Amount Parallelism\", y=\"Preprocessing Duration\", hue=\"Algorithm\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "plt.title(\"Preprocessing duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5bcd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_palette = sns.color_palette()\n",
    "palette = {\n",
    "    BASELINE_LABEL: sns_palette[0],\n",
    "    NAIVE_LABEL: sns_palette[2],\n",
    "    ADVANCED_LABEL: sns_palette[1],\n",
    "    ADVANCED_FIRST_MODEL_LABEL: sns_palette[3],\n",
    "}\n",
    "\n",
    "d = parallel_df[\n",
    "    (parallel_df[\"Algorithm\"].isin(ALGORITHMS_A_STAR_BASELINE_AND_ADVANCED))\n",
    "].copy()\n",
    "d.loc[d[\"Algorithm\"] == ALGORITHM_BASELINE_A_STAR, \"Algorithm\"] = BASELINE_LABEL\n",
    "d.loc[d[\"Algorithm\"] == ALGORITHM_TP_A_STAR_NOT_NAIVE, \"Algorithm\"] = ADVANCED_LABEL\n",
    "d = d.groupby(by=[\"Amount Parallelism\", \"Algorithm\"]).mean()\n",
    "\n",
    "sns.lineplot(\n",
    "    data=d,\n",
    "    x=\"Amount Parallelism\",\n",
    "    y=\"Preprocessing Duration\",\n",
    "    hue=\"Algorithm\",\n",
    "    palette=palette,\n",
    ")\n",
    "plt.xlabel(\"Amount of Parallelism\")\n",
    "plt.ylabel(\"Preprocessing Duration\\n(in seconds, log scale)\")\n",
    "plt.yscale(\"log\")\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [labels.index(BASELINE_LABEL), labels.index(ADVANCED_LABEL)]\n",
    "plt.legend(\n",
    "    [handles[idx] for idx in order],\n",
    "    [labels[idx] for idx in order],\n",
    "    bbox_to_anchor=(0, 1.09),\n",
    "    loc=2,\n",
    "    borderaxespad=0.0,\n",
    "    ncol=3,\n",
    ")\n",
    "Path(os.path.join(RESULTS, \"plots\", \"parallel_synthetic\")).mkdir(\n",
    "    parents=True, exist_ok=True\n",
    ")\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        RESULTS,\n",
    "        \"plots\",\n",
    "        \"parallel_synthetic\",\n",
    "        \"synthetic_parallel_logs_preprocessing_duration.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68988729",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_df[\n",
    "    (parallel_df[\"Infix Length\"] < 20)\n",
    "    & (parallel_df[\"Amount Parallelism\"] == 0.8)\n",
    "    & (parallel_df[\"Algorithm\"] == ALGORITHM_BASELINE_A_STAR)\n",
    "][\"Preprocessing Duration\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f23509",
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = [\n",
    "    ALGORITHM_BASELINE_DIJKSTRA,\n",
    "    ALGORITHM_TP_DIJKSTRA_NAIVE,\n",
    "    ALGORITHM_TP_DIJKSTRA_NOT_NAIVE,\n",
    "]\n",
    "alg_to_name = {\n",
    "    ALGORITHM_BASELINE_DIJKSTRA: BASELINE_LABEL,\n",
    "    ALGORITHM_TP_DIJKSTRA_NAIVE: NAIVE_LABEL,\n",
    "    ALGORITHM_TP_DIJKSTRA_NOT_NAIVE: ADVANCED_LABEL,\n",
    "}\n",
    "\n",
    "for alg in algs:\n",
    "    alg_f = alg_to_name[alg]\n",
    "    for prop in [j / 10 for j in range(11)]:\n",
    "        Path(\n",
    "            os.path.join(\n",
    "                RESULTS,\n",
    "                \"plots\",\n",
    "                \"parallel_synthetic\",\n",
    "                \"algorithm_\" + alg_f,\n",
    "                \"amout_parallel_\" + str(prop),\n",
    "            )\n",
    "        ).mkdir(parents=True, exist_ok=True)\n",
    "        for i in range(10):\n",
    "            filtered_df = (\n",
    "                parallel_df[\n",
    "                    (parallel_df[\"Algorithm\"] == ALGORITHM_BASELINE_DIJKSTRA)\n",
    "                    & (parallel_df[\"Amount Parallelism\"] == 0.8)\n",
    "                    & (parallel_df[\"Original Log\"] == i)\n",
    "                ]\n",
    "                .groupby(by=[\"Infix Length\"])\n",
    "                .median()\n",
    "            )\n",
    "            x = filtered_df.index\n",
    "            y = [\n",
    "                filtered_df[\"Preprocessing Duration\"],\n",
    "                filtered_df[\"Alignment Duration\"],\n",
    "            ]\n",
    "\n",
    "            plt.stackplot(x, y, labels=[\"Preprocessing Duration\", \"Alignment Duration\"])\n",
    "            plt.legend(bbox_to_anchor=(0, 1.1), loc=2, borderaxespad=0.0, ncol=3)\n",
    "            plt.xlabel(\"Infix Length\")\n",
    "            plt.ylabel(\"Duration (in seconds)\")\n",
    "            plt.savefig(\n",
    "                os.path.join(\n",
    "                    RESULTS,\n",
    "                    \"plots\",\n",
    "                    \"parallel_synthetic\",\n",
    "                    \"algorithm_\" + alg_f,\n",
    "                    \"amout_parallel_\" + str(prop),\n",
    "                    \"log_\" + str(i) + \".pdf\",\n",
    "                ),\n",
    "                bbox_inches=\"tight\",\n",
    "            )\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c23e9",
   "metadata": {},
   "source": [
    "## Compare naive and not naive runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e861b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=results_df[\n",
    "        results_df[\"Algorithm\"].isin(\n",
    "            [\n",
    "                ALGORITHM_TP_DIJKSTRA_NAIVE,\n",
    "                ALGORITHM_TP_DIJKSTRA_NOT_NAIVE,\n",
    "                ALGORITHM_BASELINE_DIJKSTRA,\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    x=\"Consumed Time\",\n",
    "    hue=\"Algorithm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436ce61",
   "metadata": {},
   "source": [
    "## Get overview of different models for different noise thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "\n",
    "NOISE_THRESHOLD = 0.99\n",
    "FILENAME = \"BPI_Challenge_2012\"\n",
    "log = xes_importer.apply(os.path.join(\"./results\", FILENAME + \".xes\"))\n",
    "tree = inductive_miner.apply_tree(\n",
    "    log,\n",
    "    variant=inductive_miner.Variants.IM_CLEAN,\n",
    "    parameters={\n",
    "        inductive_miner.Variants.IM_CLEAN.value.Parameters.NOISE_THRESHOLD: NOISE_THRESHOLD\n",
    "    },\n",
    ")\n",
    "\n",
    "gviz = pt_visualizer.apply(\n",
    "    tree,\n",
    "    parameters={pt_visualizer.Variants.WO_DECORATION.value.Parameters.FORMAT: \"png\"},\n",
    ")\n",
    "pt_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4b47c",
   "metadata": {},
   "source": [
    "# Check for infixes with different costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5489c9",
   "metadata": {},
   "source": [
    "This should never happen. All approach should determine equal minimal costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3f8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    results_df[results_df[\"Algorithm\"] == alg][[\"Infix\", \"Cost\", \"Alignment\"]]\n",
    "    for alg in ALGORITHMS\n",
    "]\n",
    "merged_df = datasets[0].rename(\n",
    "    columns={\"Cost\": \"Cost_\" + ALGORITHMS[0], \"Alignment\": \"Alignment_\" + ALGORITHMS[0]}\n",
    ")\n",
    "\n",
    "for i in range(1, len(ALGORITHMS)):\n",
    "    merged_df = merged_df.merge(\n",
    "        datasets[i].rename(\n",
    "            columns={\n",
    "                \"Cost\": \"Cost_\" + ALGORITHMS[i],\n",
    "                \"Alignment\": \"Alignment_\" + ALGORITHMS[i],\n",
    "            }\n",
    "        ),\n",
    "        on=\"Infix\",\n",
    "    )\n",
    "\n",
    "assert len(merged_df) == len(results_df) / len(ALGORITHMS)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_column_names = [\"Cost_\" + alg for alg in ALGORITHMS]\n",
    "for i in range(0, len(cost_column_names) - 1):\n",
    "    assert merged_df[cost_column_names[i]].equals(merged_df[cost_column_names[i + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb10052",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_without_timeouts = merged_df.dropna()\n",
    "print(len(merged_df_without_timeouts))\n",
    "cost_column_names = [\"Cost_\" + alg for alg in ALGORITHMS]\n",
    "for i in range(0, len(cost_column_names) - 1):\n",
    "    assert merged_df_without_timeouts[cost_column_names[i]].equals(\n",
    "        merged_df_without_timeouts[cost_column_names[i + 1]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9137e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_algorithms = [ALGORITHM_BASELINE_DIJKSTRA, ALGORITHM_TP_DIJKSTRA_NOT_NAIVE]\n",
    "compare_algorithms_c = [\"Cost_\" + alg for alg in compare_algorithms]\n",
    "compare_algorithms_a = [\"Alignment_\" + alg for alg in compare_algorithms]\n",
    "filter_columns = [\"Infix\"] + compare_algorithms_a + compare_algorithms_c\n",
    "merged_df[merged_df[compare_algorithms_c[0]] != merged_df[compare_algorithms_c[1]]][\n",
    "    filter_columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12713b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in ALGORITHMS:\n",
    "    print(alg, merged_df[\"Cost_\" + alg].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df[\"Timeout\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[726][compare_algorithms_a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f084908",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[726][compare_algorithms_a[1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
